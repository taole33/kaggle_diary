{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\n# In[30]:\n\n\nimport json\nimport re\nimport gc\nimport pickle\nimport itertools\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nimport os\nfrom datetime import datetime as dt\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport datetime\nts_conv = np.vectorize(datetime.datetime.fromtimestamp) # ut(10 digit) -> date\n\n# pandas settings -----------------------------------------\npd.set_option(\"display.max_colwidth\", 100)\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\npd.options.display.float_format = '{:,.5f}'.format\n\n# Graph drawing -------------------------------------------\nimport matplotlib\nfrom matplotlib import font_manager\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom matplotlib import rc\nfrom matplotlib_venn import venn2, venn2_circles\nfrom matplotlib import animation as ani\nfrom IPython.display import Image\nfrom pylab import imread\n\nplt.rcParams[\"patch.force_edgecolor\"] = True\nfrom IPython.display import display # Allows the use of display() for DataFrames\nimport seaborn as sns\nsns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\nsns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nred = sns.xkcd_rgb[\"light red\"]\ngreen = sns.xkcd_rgb[\"medium green\"]\nblue = sns.xkcd_rgb[\"denim blue\"]\n\nget_ipython().run_line_magic('matplotlib', 'inline')\nget_ipython().run_line_magic('config', \"InlineBackend.figure_format='retina'\")\n\n# ML -------------------------------------------\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# In[31]:\n\n\ndef unpickle(filename):\n    with open(filename, 'rb') as fo:\n        p = pickle.load(fo)\n    return p\n\ndef to_pickle(filename, obj):\n    with open(filename, 'wb') as f:\n        pickle.dump(obj, f, -1)\n\n\n\nclass FeatureStore():\n    \n    # necessayr to re-check\n    floor_convert = {'1F' :  0, '2F' : 1, '3F' : 2, '4F' : 3, '5F' : 4, \n                     '6F' : 5, '7F' : 6, '8F' : 7, '9F' : 8,\n                     'B'  : -1, 'B1' : -1, 'B2' : -2, 'B3' : -3, \n                     'BF' : -1, 'BM' : -1, \n                     'F1' : 0, 'F2' : 1, 'F3' : 2, 'F4' : 3, 'F5' : 4, \n                     'F6' : 5, 'F7' : 6, 'F8' : 7, 'F9' : 8, 'F10': 9,\n                     'L1' : 0, 'L2' : 1, 'L3' : 2, 'L4' : 3, 'L5' : 4, \n                     'L6' : 5, 'L7' : 6, 'L8' : 7, 'L9' : 8, 'L10': 9, \n                     'L11': 10,\n                     'G'  : 0, 'LG1': 0, 'LG2': 1, 'LM' : 0, 'M'  : 0, \n                     'P1' : 0, 'P2' : 1,}\n    \n    df_types = ['accelerometer',\n                'accelerometer_uncalibrated',\n                'beacon',\n                'gyroscope',\n                'gyroscope_uncalibrated',\n                'magnetic_field',\n                'magnetic_field_uncalibrated',\n                'rotation_vector',\n                'waypoint',\n                'wifi']\n    \n    # https://github.com/location-competition/indoor-location-competition-20\n    df_type_cols = {'accelerometer': [\"timestamp\", \"x\", \"y\", \"z\", \"accuracy\"],\n                'accelerometer_uncalibrated': [\"timestamp\", \"x\", \"y\", \"z\", \n                                               \"x2\", \"y2\", \"z2\", \"accuracy\" ],\n                'beacon': [\"timestamp\", \"uuid\", \"major_id\", \"minor_id\", \"tx_power\", \n                           \"rssi\", \"distance\", \"mac_addr\", \"timestamp2\"],\n                'gyroscope': [\"timestamp\", \"x\", \"y\", \"z\", \"accuracy\"],\n                'gyroscope_uncalibrated': [\"timestamp\", \"x\", \"y\", \"z\", \n                                           \"x2\", \"y2\", \"z2\", \"accuracy\" ],\n                'magnetic_field': [\"timestamp\", \"x\", \"y\", \"z\", \"accuracy\"],\n                'magnetic_field_uncalibrated': [\"timestamp\", \"x\", \"y\", \"z\", \n                                                \"x2\", \"y2\", \"z2\", \"accuracy\" ],\n                'rotation_vector': [\"timestamp\", \"x\", \"y\", \"z\", \"accuracy\"],\n                'waypoint': [\"timestamp\", \"x\", \"y\"],\n                'wifi': [\"timestamp\", \"ssid\", \"bssid\",\"rssi\",\"frequency\",\n                         \"last_seen_timestamp\",]}\n\n    dtype_dict = {}\n    dtype_dict[\"accelerometer\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \"z\":float, \n                                   \"accuracy\":int}\n    dtype_dict[\"accelerometer_uncalibrated\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \n                                                \"z\":float, \"x2\":float, \"y2\":float, \n                                                \"z2\":float, \"accuracy\":int}\n    dtype_dict[\"beacon\"] = {\"timestamp\":int, \"uuid\":str, \"major_id\":str, \n                            \"minor_id\":str, \"tx_power\":int,  \"rssi\":int, \n                            \"distance\":float, \"mac_addr\":str, \"timestamp2\":int}\n    dtype_dict[\"gyroscope\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \"z\":float, \n                               \"accuracy\":int}\n    dtype_dict[\"gyroscope_uncalibrated\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \n                                            \"z\":float, \"x2\":float, \"y2\":float, \n                                            \"z2\":float, \"accuracy\":int}\n    dtype_dict[\"magnetic_field\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \n                                    \"z\":float, \"accuracy\":int}\n    dtype_dict[\"magnetic_field_uncalibrated\"] = {\"timestamp\":int, \"x\":float, \n                                                 \"y\":float, \"z\":float, \"x2\":float, \n                                                 \"y2\":float, \"z2\":float, \"accuracy\":int}\n    dtype_dict[\"rotation_vector\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \n                                     \"z\":float, \"accuracy\":int}\n    dtype_dict[\"waypoint\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \"z\":float}\n    dtype_dict[\"wifi\"] = {\"timestamp\":int, \"ssid\":str, \"bssid\":str,\n                          \"rssi\":int,\"frequency\":int, \"last_seen_timestamp\":int}\n\n    def __init__(self, site_id, floor, path_id, \n                 input_path=\"../input/indoor-location-navigation/\",\n                 save_path=\"../mid\"):\n        self.site_id = site_id.strip()\n        self.floor = floor.strip()\n        self.n_floor = 0 #self.floor_convert[self.floor]\n        self.path_id = path_id.strip()\n        \n        self.input_path = input_path\n        assert Path(input_path).exists(), f\"input_path do not exist: {input_path}\"\n        \n        self.save_path = save_path\n        Path(save_path).mkdir(parents=True, exist_ok=True)\n        \n        self.site_info = SiteInfo(site_id=self.site_id, floor=self.floor, input_path=self.input_path)\n        \n    def _flatten(self, l):\n        return list(itertools.chain.from_iterable(l))\n    \n    def multi_line_spliter(self, s):\n        matches = re.finditer(\"TYPE_\", s)\n        matches_positions = [match.start() for match in matches]\n        split_idx = [0] + [matches_positions[i]-14 for i in range(1, len(matches_positions))] + [len(s)]\n        return [s[split_idx[i]:split_idx[i+1]] for i in range(len(split_idx)-1)]\n    \n    def load_df(self, ):\n        path = str(Path(self.input_path)/f\"test/{self.path_id}.txt\")\n        with open(path) as f:\n            data = f.readlines()\n        \n        modified_data = []\n        for s in data:\n            if s.count(\"TYPE_\")>1:\n                lines = self.multi_line_spliter(s)\n                modified_data.extend(lines)\n            else:\n                modified_data.append(s)\n        del data\n        self.meta_info_len = len([d for d in modified_data if d[0]==\"#\"])\n        self.meta_info_df = pd.DataFrame([m.replace(\"\\n\", \"\").split(\":\") \n                                          for m in self._flatten([d.split(\"\\t\") \n                                                                  for d in modified_data if d[0]==\"#\"]) if m!=\"#\"])\n\n        data_df = pd.DataFrame([d.replace(\"\\n\", \"\").split(\"\\t\") for d in modified_data if d[0]!=\"#\"])\n        for dt in self.df_types:\n            # select data type\n            ##ここ\n            df_s = data_df[data_df[1]==f\"TYPE_{dt.upper()}\"]\n            if len(df_s)==0:\n                setattr(self, dt, pd.DataFrame(columns=self.df_type_cols[dt]))\n            else:\n                # remove empty cols\n                na_info = df_s.isna().sum(axis=0) == len(df_s)\n                df_s = df_s[[i for i in na_info[na_info==False].index if i!=1]].reset_index(drop=True)\n                \n                if len(df_s.columns)!=len(self.df_type_cols[dt]):\n                    df_s.columns = self.df_type_cols[dt][:len(df_s.columns)]\n                else:\n                    df_s.columns = self.df_type_cols[dt]\n            \n                # set dtype          \n                for c in df_s.columns:\n                    \n                    #ここ\n                    df_s[c] = df_s[c].astype(self.dtype_dict[dt][c])\n                                     \n                # set DataFrame to attr\n                setattr(self, dt, df_s)\n    \n    def get_site_info(self, keep_raw=False):\n        self.site_info.get_site_info(keep_raw=keep_raw)\n            \n    def load_all_data(self, keep_raw=False):     \n        self.load_df()\n        self.get_site_info(keep_raw=keep_raw)\n        \n    def __getitem__(self, item):\n        if item in self.df_types:\n            return getattr(self, item)\n        else:\n            return None\n    \n    def save(self, ):\n        # to be implemented\n        pass\n    \n    \nclass SiteInfo():\n    def __init__(self, site_id, floor, input_path=\"../input/indoor-location-navigation/\"):\n        self.site_id = site_id\n        self.floor = floor\n        self.input_path = input_path\n        assert Path(input_path).exists(), f\"input_path do not exist: {input_path}\"\n        \n    def get_site_info(self, keep_raw=False):\n        floor_info_path = \"../input/indoor-location-navigation/metadata/5a0546857ecc773753327266/B1/floor_info.json\"\n        with open(floor_info_path, \"r\") as f:\n            self.floor_info = json.loads(f.read())\n            self.site_height = self.floor_info[\"map_info\"][\"height\"]\n            self.site_width = self.floor_info[\"map_info\"][\"width\"]\n            if not keep_raw:\n                del self.floor_info\n            \n        geojson_map_path = \"../input/indoor-location-navigation/metadata/5a0546857ecc773753327266/B1/geojson_map.json\"\n        with open(geojson_map_path, \"r\") as f:\n            self.geojson_map = json.loads(f.read())\n            self.map_type = self.geojson_map[\"type\"]\n            self.features = self.geojson_map[\"features\"]\n            \n            self.floor_coordinates = self.features[0][\"geometry\"][\"coordinates\"]\n            self.store_coordinates = [self.features[i][\"geometry\"][\"coordinates\"] \n                                          for i in range(1, len(self.features))]\n                \n            if not keep_raw:\n                del self.geojson_map\n    \n    def show_site_image(self):\n        path = \"../input/indoor-location-navigation/metadata/5a0546857ecc773753327266/B1/floor_image.png\"\n        plt.imshow(imread(path), extent=[0, self.site_width, 0, self.site_height])\n\n    def draw_polygon(self, size=8, only_floor=False):\n\n        fig = plt.figure()\n        ax = plt.subplot(111)\n            \n        xmax, xmin, ymax, ymin = self._draw(self.floor_coordinates, ax, calc_minmax=True)\n        if not only_floor:\n            self._draw(self.store_coordinates, ax, fill=True)\n        plt.legend([])\n        \n        xrange = xmax - xmin\n        yrange = ymax - ymin\n        ratio = yrange / xrange\n        \n        self.x_size = size\n        self.y_size = size*ratio\n\n        fig.set_figwidth(size)\n        fig.set_figheight(size*ratio)\n        # plt.show()\n        return ax\n        \n    def _draw(self, coordinates, ax, fill=False, calc_minmax=False):\n        xmax, ymax = -np.inf, -np.inf\n        xmin, ymin = np.inf, np.inf\n        for i in range(len(coordinates)):\n            ndim = np.ndim(coordinates[i])\n            if ndim==2:\n                corrd_df = pd.DataFrame(coordinates[i])\n                if fill:\n                    ax.fill(corrd_df[0], corrd_df[1], alpha=0.7)\n                else:\n                    corrd_df.plot.line(x=0, y=1, style=\"-\", ax=ax)\n                        \n                if calc_minmax:\n                    xmax = max(xmax, corrd_df[0].max())\n                    xmin = min(xmin, corrd_df[0].min())\n\n                    ymax = max(ymax, corrd_df[1].max())\n                    ymin = min(ymin, corrd_df[1].min())\n            elif ndim==3:\n                for j in range(len(coordinates[i])):\n                    corrd_df = pd.DataFrame(coordinates[i][j])\n                    if fill:\n                        ax.fill(corrd_df[0], corrd_df[1], alpha=0.6)\n                    else:\n                        corrd_df.plot.line(x=0, y=1, style=\"-\", ax=ax)\n                        \n                    if calc_minmax:\n                        xmax = max(xmax, corrd_df[0].max())\n                        xmin = min(xmin, corrd_df[0].min())\n\n                        ymax = max(ymax, corrd_df[1].max())\n                        ymin = min(ymin, corrd_df[1].min())\n            else:\n                assert False, f\"ndim of coordinates should be 2 or 3: {ndim}\"\n        if calc_minmax:\n            return xmax, xmin, ymax, ymin\n        else:\n            return None\n         \n\n\n# In[32]:\n\n\n# site_meta_data\nsite_meta_data = pd.DataFrame([[p.split(\"/\")[-2], p.split(\"/\")[-1]] for p in glob(\"../input/indoor-location-navigation/metadata/**/*\")])\nsite_meta_data.columns = [\"site_id\", \"floor\"]\nsite_meta_data.head()\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                    site_id floor\n0  5cd56c0ce2acfd2d33b6ab27    B1\n1  5cd56c0ce2acfd2d33b6ab27    F3\n2  5cd56c0ce2acfd2d33b6ab27    F2\n3  5cdbc652853bc856e89a8694    B1\n4  5cdbc652853bc856e89a8694    F1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>site_id</th>\n      <th>floor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5cd56c0ce2acfd2d33b6ab27</td>\n      <td>B1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5cd56c0ce2acfd2d33b6ab27</td>\n      <td>F3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5cd56c0ce2acfd2d33b6ab27</td>\n      <td>F2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5cdbc652853bc856e89a8694</td>\n      <td>B1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5cdbc652853bc856e89a8694</td>\n      <td>F1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"'''\n# train_meta_data\n#globはパスをlist形式で取得できる。train_metaにtrain以下のパスの文字列を全部入れている。\ntrain_meta = glob(\"../input/indoor-location-navigation/train/*/*/*\")\n\n#train_metaをpdの形式にする。（4桁行×1列の表形式）\ntrain_meta_org = pd.DataFrame(train_meta)\n\n#train_meta_orgはパス名が入ってるので、パス名から建物名と、フロア名、ファイル名（＝＝.txt）を取り出す。\n#以下の形\n#0      5cd56c0ce2acfd2d33b6ab27   B1  5d09a625bd54340008acddb9.txt\n#1      5cd56c0ce2acfd2d33b6ab27   B1  5d09a625bd54340008acddb7.txt\ntrain_meta = train_meta_org[0].str.split(\"/\", expand=True)[[4, 5, 6]]\n\n#列名を付けてあげる\ntrain_meta.columns = [\"site_id\", \"floor\", \"path_id\"]\n\n#.txtをとる\ntrain_meta[\"path_id\"] = train_meta[\"path_id\"].str.replace(\".txt\", \"\")\n\n#path列を追加して、そこにパスを代入する（train_meta_orgの0列目にパスが入ってる）\ntrain_meta[\"path\"] = train_meta_org[0]\n#train_meta.head()\n'''","metadata":{"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'\\n# train_meta_data\\n#globはパスをlist形式で取得できる。train_metaにtrain以下のパスの文字列を全部入れている。\\ntrain_meta = glob(\"../input/indoor-location-navigation/train/*/*/*\")\\n\\n#train_metaをpdの形式にする。（4桁行×1列の表形式）\\ntrain_meta_org = pd.DataFrame(train_meta)\\n\\n#train_meta_orgはパス名が入ってるので、パス名から建物名と、フロア名、ファイル名（＝＝.txt）を取り出す。\\n#以下の形\\n#0      5cd56c0ce2acfd2d33b6ab27   B1  5d09a625bd54340008acddb9.txt\\n#1      5cd56c0ce2acfd2d33b6ab27   B1  5d09a625bd54340008acddb7.txt\\ntrain_meta = train_meta_org[0].str.split(\"/\", expand=True)[[4, 5, 6]]\\n\\n#列名を付けてあげる\\ntrain_meta.columns = [\"site_id\", \"floor\", \"path_id\"]\\n\\n#.txtをとる\\ntrain_meta[\"path_id\"] = train_meta[\"path_id\"].str.replace(\".txt\", \"\")\\n\\n#path列を追加して、そこにパスを代入する（train_meta_orgの0列目にパスが入ってる）\\ntrain_meta[\"path\"] = train_meta_org[0]\\n#train_meta.head()\\n'"},"metadata":{}}]},{"cell_type":"code","source":"\n#test_metaの作成\n\nsample_sub = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv')\ntest_sites = sample_sub.site_path_timestamp.apply(lambda x: pd.Series(x.split(\"_\")))[0].unique().tolist()\n\ntest_meta = sample_sub[\"site_path_timestamp\"].apply(\n    lambda x: pd.Series(x.split(\"_\")))\ntest_meta.columns = [\"site_id\", \"path_id\", \"timestamp\"]\n#test_meta=test_meta.drop('timestamp', axis=1)\ntest_meta = test_meta.drop_duplicates(subset=[\"site_id\", \"path_id\"]).reset_index(drop=True)\n\ntest_meta \n\n\n#floorだけない\n\n\n# In[38]:\n\n\ndef pickle_dump_dill(obj, path):\n    with open(path, mode='wb') as f:\n        dill.dump(obj, f)\n\n\ndef pickle_load_dill(path):\n    with open(path, mode='rb') as f:\n        data = dill.load(f)\n        return data","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#featureで繰り返す数を抽出\nsample_sub = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv')\ntest_sites = sample_sub.site_path_timestamp.apply(lambda x: pd.Series(x.split(\"_\")))[0].unique().tolist()\n\ntest_meta = sample_sub[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\ntest_meta.columns = [\"site_id\", \"path_id\", \"timestamp\"]\n#test_meta=test_meta.drop('timestamp', axis=1)\ntest_meta['site+path'] = test_meta['site_id'].str.cat(test_meta['path_id'])\n#test_meta = test_meta.drop_duplicates(subset=[\"site_id\", \"path_id\"]).reset_index(drop=True)\n\n#site.pathに入ってるwaypointの数をsite＿path:個数でdictに格納\n#あとでsite_pathで検索して回数を取り出す\ncount_dict = test_meta['site+path'].value_counts(sort=False).to_dict()","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#train_meta_sub.head(50)","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#a=train_meta_sub[train_meta_sub['site+path']=='5a0546857ecc7737533272660c06cc9f21d172618d74c6c8']","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#a.index[0]","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\ncreate_train_meta_sub=True\nrow=0\n\nif create_train_meta_sub:\n    #train_get_row_n = train_meta[train_meta['site_id'].isin(test_sites)].reset_index(drop=True)\n    #train_meta_sub['site_id']=0\n    train_meta_sub = test_meta[test_meta['site_id'].isin(test_sites)].reset_index(drop=True)\n\n#                        site_id floor                   path_id  \\\n#0      5da138764db8ce0c98bcaa46    B1  5dabdb5e18410e00067e6fe2   \n#                            ↓\n#site_id                   path_id\n#0    5a0546857ecc773753327266  046cfa46be49fc10834815c6\n\n#列を作成\n    my_train = pd.DataFrame()\n    my_train['site_id']=0\n    my_train['floor']=0\n    my_train['path_id']=0\n    my_train['path']=0\n    \n    #for i in tqdm(range(len(train_meta_sub))):\n    for i in tqdm(range(0,10132)):\n        \n        \n        \n        feature = FeatureStore(site_id=train_meta_sub.iloc[i]['site_id'], floor=\"BF\", path_id=train_meta_sub.iloc[i]['path_id'])\n        feature.load_all_data() \n        #start_time=int(feature.meta_info_df[feature.meta_info_df[0]=='startTime'][1])\n        #end_time=int(feature.meta_info_df[feature.meta_info_df[0]=='endTime'][1])\n\n        k=0\n        m=0\n        wifi_unique_timestamp = feature.wifi[\"timestamp\"].unique()\n        site_path = train_meta_sub.iloc[i]['site_id']+train_meta_sub.iloc[i]['path_id']\n        my_train.loc[row,'site_id']=train_meta_sub.iloc[i]['site_id']\n        my_train.loc[row,'floor']= 999\n        my_train.loc[row,'path_id']=train_meta_sub.iloc[i]['path_id']\n        waypoint_time = int(train_meta_sub.iloc[i]['timestamp'])\n        my_train.loc[row,'wp_time']=waypoint_time\n        \n        #for j in range(count_dict[site_path]):\n    \n            #waypoint_time = int(train_meta_sub.iloc[i]['timestamp'])\n            #my_train.loc[row,'site_id']=feature.site_id\n            #my_train.loc[row,'floor']=feature.n_floor\n            #my_train.loc[row,'path_id']=feature.path_id\n            #my_train.loc[row,'path']=feature.input_path\n            #my_train.loc[row,'wp_time']=waypoint_time\n            #my_train.loc[row,'x']=feature.waypoint.iloc[j]['x']\n            #my_train.loc[row,'y']=feature.waypoint.iloc[j]['y']\n            #my_train.loc[row,'start_time']=start_time\n            #my_train.loc[row,'end_time']=end_time\n            #my_train.loc[row,'next_to_acce_X']=0\n            #my_train.loc[row,'next_to_acce_Y']=0\n            #my_train.loc[row,'next_to_acce_Z']=0\n            \n            #wifiが近い5件を追加する。（wifi[0]には一番近いデータが入っている）\n        wifi_time_dict = {}\n        for m in range(len(wifi_unique_timestamp)):\n            wifi_abs=abs(wifi_unique_timestamp[m]-waypoint_time)\n            wifi_time_dict[wifi_unique_timestamp[m]] = wifi_abs\n                    \n        if not len(wifi_time_dict) == 0:\n            #一番差が小さいtimestampを抽出\n            wifi_nearest = min(wifi_time_dict, key=wifi_time_dict.__getitem__)\n            wifi_nearest_time = feature.wifi.index[feature.wifi['timestamp'] == wifi_nearest]\n            #print(wifi_nearest_time)\n            if len(wifi_nearest_time)<=5:\n                fornum = len(wifi_nearest_time)\n            else:\n                fornum = 5\n            for n in range(fornum):\n                my_train.loc[row,'wifi_timestamp']=feature.wifi.iloc[wifi_nearest_time[n]]['timestamp']\n                        #my_train.loc[row,'wifi_ssid' + str(n)]=feature.wifi.iloc[m+n]['ssid']]\n                my_train.loc[row,'wifi_bssid' + str(n)]=feature.wifi.iloc[wifi_nearest_time[n]]['bssid']\n                my_train.loc[row,'wifi_rssi' + str(n)]=feature.wifi.iloc[wifi_nearest_time[n]]['rssi']\n                    \n                my_train.loc[row,'wifi_frequency' + str(n)]=feature.wifi.iloc[wifi_nearest_time[n]]['frequency']\n            \n            \n            #beacon(直近の時間)を追加する。（複数のbeaconを追加するとか考えられるかも）\n        for m in range(len(feature.beacon)):\n            beacon_time = feature.beacon.iloc[m][\"timestamp\"]\n                #ここのif文は改良の余地あり。timestampが超えても、よりtimeが近いデータがあればそちらを採用した方が良い。\n            if beacon_time < waypoint_time:\n                my_train.loc[row,'beacon_timestamp']=feature.beacon.iloc[m]['timestamp']\n                    #my_train.loc[row,'wifi_ssid' + str(n)]=feature.wifi.iloc[m+n]['ssid']\n                my_train.loc[row,'beacon_minorid']=feature.beacon.iloc[m]['minor_id']\n                my_train.loc[row,'beacon_rssi']=feature.beacon.iloc[m]['rssi']\n                my_train.loc[row,'beacon_distance']=feature.beacon.iloc[m]['distance']\n            else:\n                break\n            #なんか有効な特徴量を追加する。timestampがtimestamp<wp_timeとなっているデータを特徴量とする。\n            \n            \n        x=0\n        y=0\n        z=0\n        for k in range(len(feature.accelerometer)-1):\n            acce_time = feature.accelerometer.iloc[k][\"timestamp\"]\n                \n                #test_dataの時は、waypoint_time=submission_dataのtimeなので処理が必要\n  \n                #xyzの時間は1個後のwaypointに対応したもの。\n            #if not i+k+1==len(feature.waypoint):\n\n            if my_train.loc[row,'wifi_timestamp']<acce_time<waypoint_time:\n                x += (feature.accelerometer.iloc[k+1][\"timestamp\"]-acce_time) * feature.accelerometer.iloc[k][\"x\"]\n                y += (feature.accelerometer.iloc[k+1][\"timestamp\"]-acce_time) * feature.accelerometer.iloc[k][\"y\"]\n                z += (feature.accelerometer.iloc[k+1][\"timestamp\"]-acce_time) * feature.accelerometer.iloc[k][\"z\"]\n                my_train.loc[row,'next_to_acce_X']= x\n                my_train.loc[row,'next_to_acce_Y']= y\n                my_train.loc[row,'next_to_acce_Z']= z\n                    \n                    #こっちがメイン\n            elif my_train.loc[row,'wifi_timestamp']>acce_time>waypoint_time:\n                x +=  (feature.accelerometer.iloc[k+1][\"timestamp\"]-acce_time) * feature.accelerometer.iloc[k][\"x\"]\n                y += (feature.accelerometer.iloc[k+1][\"timestamp\"]-acce_time) * feature.accelerometer.iloc[k][\"y\"]\n                z += (feature.accelerometer.iloc[k+1][\"timestamp\"]-acce_time) * feature.accelerometer.iloc[k][\"z\"]\n                my_train.loc[row,'next_to_acce_X']= x\n                my_train.loc[row,'next_to_acce_Y']= y\n                my_train.loc[row,'next_to_acce_Z']= z\n            \n        \n        row += 1\n            \n    my_train.to_csv('test0-10132.csv', index=False)\nelse:\n    my_train = pd.read_csv('../input/indoor-public/my_train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  9%|▉         | 954/10132 [41:26<32:32:29, 12.76s/it]","output_type":"stream"}]},{"cell_type":"code","source":"my_train.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}